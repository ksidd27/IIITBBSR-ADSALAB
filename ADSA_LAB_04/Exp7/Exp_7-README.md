# Huffman Coding in C (Text Compression)

## üìå Overview

This project implements **Huffman Coding**, a lossless compression algorithm that reduces the size of text by assigning **shorter binary codes to frequent characters** and **longer codes to less frequent characters**.

The program:

‚úî Reads any input string (up to 1000 characters)  
‚úî Computes character frequencies  
‚úî Builds a Huffman Tree  
‚úî Generates Huffman codes for each character  
‚úî Prints original input  
‚úî Prints generated Huffman codes  
‚úî Prints the final encoded binary message  

---

## üß† What is Huffman Coding?

Huffman Coding is a **greedy algorithm** used for **lossless data compression**.

### Key ideas:
- Characters with higher frequency receive **shorter codes**.
- Characters with lower frequency receive **longer codes**.
- The algorithm constructs a **binary tree (Huffman Tree)** where:
  - Leaf nodes store characters
  - Internal nodes store the sum of child frequencies
- Traversing left = `0`, right = `1`
- Codes are generated from root to leaves.

---

## üìÇ Features of This Implementation

### ‚úî Supports all ASCII characters  
### ‚úî Automatically calculates frequencies  
### ‚úî Builds Huffman tree without priority queue (simplified approach)  
### ‚úî Displays:  
- Original message  
- Huffman code for each character  
- Fully encoded binary message  

---

## üì• Input Format

The program takes **any string** as input:  
Enter text (max 1000 chars): hello huffman  


---

## üì§ Output Format

Original Message: hello huffman  

Huffman Codes for each character:  
'h': 01  
'e': 110  
'l': 10  
'o': 111  
' ': 00  
'u': 1010  
'f': 1011  
'm': 011  
'a': 010  

Final Encoded Message:  
01 110 10 10 111 ...  


(The actual codes depend on character frequencies.)

---

## üèó How the Code Works

### 1Ô∏è‚É£ **Count frequencies of each character**  
Stores only characters with frequency > 0.

### 2Ô∏è‚É£ **Create nodes** for each character  
Each node contains:
- character  
- frequency  
- left child  
- right child  

### 3Ô∏è‚É£ **Build Huffman Tree**  
Repeatedly:
- Pick **two smallest frequency nodes**  
- Combine into a new parent node

### 4Ô∏è‚É£ **Generate codes** by DFS traversal  
Left ‚Üí 0  
Right ‚Üí 1  

### 5Ô∏è‚É£ **Encode the full message** by concatenating all codes.

---

## ‚è≥ Time & Space Complexity

### ‚úî **Frequency Counting**
- **Time:** `O(n)`  
- **Space:** `O(1)` (fixed array of size 256)

---

### ‚úî **Building Huffman Tree (Simplified Approach)**
Instead of priority queue (min-heap), this code uses linear scanning to find the smallest nodes.

- Finding two minimums each iteration ‚Üí `O(size)`
- Tree building performed `(size - 1)` times

**Time Complexity:**  
O(size¬≤)  
(size = number of distinct characters, max 256)  


**Space Complexity:**  
O(size)  

(nodes + arrays)

---

### ‚úî **Generating Huffman Codes**
DFS traversal of tree:

- **Time:** `O(size)`  
- **Space:** `O(size √ó height)` worst case

---

### ‚úî **Encoding the message**
For input length `n`:

- **Time:** `O(n √ó L)`  
  where `L` = average code length

- **Space:** `O(n √ó L)` for encoded string

---

### Overall Complexity Summary

| Step | Time Complexity | Space Complexity |
|------|------------------|------------------|
| Counting frequencies | O(n) | O(1) |
| Building Huffman Tree | O(size¬≤) | O(size) |
| Generating codes | O(size) | O(size) |
| Encoding message | O(n √ó L) | O(n √ó L) |
| **Total** | **O(n + size¬≤)** | **O(n √ó L)** |

Where:  
- `n` = input length  
- `size` = distinct characters (‚â§256)

